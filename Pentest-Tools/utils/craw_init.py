import os
import shlex
import subprocess


def execute_crawl(domain):
    wd = os.getcwd()
    crawl_location = "VulnTester"
    os.chdir(crawl_location)
    process = subprocess.Popen(shlex.split(
        f"scrapy crawl gather_details -a domain={domain} -o forms.json"),
        stdout=subprocess.PIPE,
        universal_newlines=True)

    while True:
        return_code = process.poll()
        if return_code is not None:
            print('RETURN CODE', return_code)
            os.chdir(wd)
            return 1
